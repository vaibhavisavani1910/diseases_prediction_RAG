{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_token = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from transformers import LlamaForCausalLM, LlamaTokenizer\n",
    "import torch\n",
    "\n",
    "# Step 1: Initialize the FAISS Vector Store\n",
    "def initialize_vector_store(data_path, embedding_model_name=\"sentence-transformers/all-MiniLM-L6-v2\"):\n",
    "    \"\"\"\n",
    "    Initialize FAISS vector store from a text dataset.\n",
    "\n",
    "    Args:\n",
    "        data_path (str): Path to the text dataset.\n",
    "        embedding_model_name (str): HuggingFace embedding model name.\n",
    "\n",
    "    Returns:\n",
    "        FAISS: Initialized FAISS vector store.\n",
    "    \"\"\"\n",
    "    \n",
    "    output_file = 'fine_tuning_diseases.txt'\n",
    "\n",
    "    with open(output_file, \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "    # Split data into individual entries for FAISS\n",
    "    retriever_data = [{\"text\": line.strip()} for line in lines]\n",
    " \n",
    "\n",
    "    # Step 2: Build FAISS Index\n",
    "    embedding_model_name = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "    embedding_model = HuggingFaceEmbeddings(model_name=embedding_model_name)\n",
    "\n",
    "    # Initialize FAISS retriever\n",
    "    vectorstore = FAISS.from_texts(\n",
    "        texts=[doc[\"text\"] for doc in retriever_data],\n",
    "        embedding=embedding_model\n",
    "    )\n",
    "    return vectorstore\n",
    "\n",
    "# Step 2: Load LLaMA Model and Tokenizer\n",
    "def load_llama_model_and_tokenizer(model_path=\"meta-llama/Llama-2-7b-chat-hf\"):\n",
    "    \"\"\"\n",
    "    Load the LLaMA model and tokenizer.\n",
    "\n",
    "    Args:\n",
    "        model_path (str): Path to the LLaMA model.\n",
    "\n",
    "    Returns:\n",
    "        LlamaForCausalLM, LlamaTokenizer: Loaded model and tokenizer.\n",
    "    \"\"\"\n",
    "    tokenizer = LlamaTokenizer.from_pretrained(model_path)\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "    model = LlamaForCausalLM.from_pretrained(model_path, torch_dtype=torch.float16, device_map=\"auto\")\n",
    "    return model, tokenizer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:18<00:00,  9.35s/it]\n",
      "Some parameters are on the meta device because they were offloaded to the disk.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Initialize FAISS vector store\n",
    "data_path = \"fine_tuning_diseases.txt\"\n",
    "vectorstore = initialize_vector_store(data_path)\n",
    "\n",
    "# Load LLaMA model and tokenizer\n",
    "model_path = \"meta-llama/Llama-2-7b-chat-hf\"\n",
    "model, tokenizer = load_llama_model_and_tokenizer(model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Define the Disease Identification Function\n",
    "def identify_disease_with_context(symptoms, vectorstore, model, tokenizer, max_length=250, k=1):\n",
    "    \"\"\"\n",
    "    Predicts a disease based on symptoms and retrieved context.\n",
    "\n",
    "    Args:\n",
    "        symptoms (str): Input symptoms provided by the user.\n",
    "        vectorstore (FAISS): FAISS vector store for context retrieval.\n",
    "        model: LLaMA model.\n",
    "        tokenizer: Tokenizer for the LLaMA model.\n",
    "        max_length (int): Maximum length for the generated response.\n",
    "        k (int): Number of top documents to retrieve for context.\n",
    "\n",
    "    Returns:\n",
    "        str: Predicted disease or an appropriate message.\n",
    "    \"\"\"\n",
    "    # Retrieve context from the vector store\n",
    "    query = f\"Symptoms: {symptoms}\"\n",
    "    results = vectorstore.similarity_search(query, k=k)\n",
    "    context = \" \".join([doc.page_content for doc in results]) if results else \"No relevant context available.\"\n",
    "\n",
    "    # Create input text with retrieved context\n",
    "    input_text = (\n",
    "        \"You are a medical assistant trained to predict diseases based on symptoms.\\n\\n\"\n",
    "        f\"Context: {context}\\n\"\n",
    "        f\"Symptoms: {symptoms}\\n\\n\"\n",
    "        \"Based on the context and symptoms, provide the name of the disease. \"\n",
    "        \"If the context does not contain the answer, respond with: 'I don't know the answer.'\"\n",
    "    )\n",
    "    input_ids = tokenizer.encode(input_text, return_tensors=\"pt\")\n",
    "    input_ids = input_ids.to(model.device)\n",
    "    \n",
    "    # Generate response\n",
    "    outputs = model.generate(\n",
    "        input_ids,\n",
    "        max_length=min(len(input_ids[0]) + 50, tokenizer.model_max_length),\n",
    "        top_k=50,\n",
    "        top_p=0.95,\n",
    "        pad_token_id=tokenizer.eos_token_id,\n",
    "    )\n",
    "    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "    # Extract diagnosis from the response\n",
    "    response_lines = response.strip().split(\"\\n\")\n",
    "    for line in response_lines:\n",
    "        if \"this could be the disease:\" in line:\n",
    "            # Extract the disease name after the phrase\n",
    "            disease_name = line.split(\"this could be the disease:\")[-1].strip()\n",
    "            if disease_name:\n",
    "                # Remove any trailing period\n",
    "                disease_name = disease_name.rstrip(\".\")\n",
    "                return disease_name  # Return the extracted disease name\n",
    "    return response\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Disease: Aneurysm (abdominal aortic)\n"
     ]
    }
   ],
   "source": [
    "# Predict disease based on symptoms\n",
    "user_symptoms = \"I have deep, constant pain in my belly and back, and I feel a pulse near my bellybutton.\"\n",
    "diagnosis = identify_disease_with_context(user_symptoms, vectorstore, model, tokenizer)\n",
    "\n",
    "print(f\"Predicted Disease: {diagnosis}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Disease: Bacterial vaginosis\n"
     ]
    }
   ],
   "source": [
    "# Predict disease based on symptoms\n",
    "user_symptoms = \"I’m experiencing a thin, gray vaginal discharge with a fishy odor and itching. What might this indicate?\"\n",
    "diagnosis = identify_disease_with_context(user_symptoms, vectorstore, model, tokenizer)\n",
    "\n",
    "print(f\"Predicted Disease: {diagnosis}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 91.30%\n",
      "\n",
      "Mismatched Cases:\n",
      "Symptoms: I have deep, constant pain in my belly and back, and I feel a pulse near my bellybutton. What could this be?\n",
      "Actual Disease: abdominal aortic aneurysm\n",
      "Predicted Disease: aneurysm (abdominal aortic)\n",
      "--------------------------------------------------\n",
      "Symptoms: I’m having trouble swallowing, and sometimes it feels like food is stuck in my throat. I’ve also lost some weight. What might be going on?\n",
      "Actual Disease: achalasia\n",
      "Predicted Disease: swallowing problems\n",
      "--------------------------------------------------\n",
      "Symptoms: I feel severe pain in my upper right belly that spreads to my shoulder, and I’ve been feeling nauseous and feverish. What could this mean?\n",
      "Actual Disease: acute cholecystitis\n",
      "Predicted Disease: cholecystitis (acute)\n",
      "--------------------------------------------------\n",
      "Symptoms: I’ve been losing hearing on one side, and there’s ringing in my ear. Sometimes I feel dizzy and off balance. What might this be?\n",
      "Actual Disease: acoustic neuroma (vestibular schwannoma)\n",
      "Predicted Disease: vestibular schwannoma\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def evaluate_model(test_file_path, vectorstore, model, tokenizer, k=1):\n",
    "    \"\"\"\n",
    "    Evaluate the model on a test dataset.\n",
    "\n",
    "    Args:\n",
    "        test_file_path (str): Path to the CSV file containing the test dataset.\n",
    "        vectorstore (FAISS): FAISS vector store for context retrieval.\n",
    "        model: LLaMA model.\n",
    "        tokenizer: Tokenizer for the LLaMA model.\n",
    "        k (int): Number of top documents to retrieve for context.\n",
    "\n",
    "    Returns:\n",
    "        accuracy (float): Accuracy of the model.\n",
    "        mismatched_cases (list): List of mismatched cases.\n",
    "    \"\"\"\n",
    "    # Load the test dataset\n",
    "    test_df = pd.read_csv(test_file_path)\n",
    "\n",
    "    correct_predictions = 0\n",
    "    total_predictions = len(test_df)\n",
    "    mismatched_cases = []\n",
    "\n",
    "    for _, row in test_df.iterrows():\n",
    "        # Extract symptoms and actual disease\n",
    "        symptoms = row[\"symptoms\"]\n",
    "        actual_disease = row[\"disease\"].strip().lower()\n",
    "\n",
    "        # Predict disease using the model\n",
    "        predicted_disease = identify_disease_with_context(symptoms, vectorstore, model, tokenizer, k=k)\n",
    "        predicted_disease = predicted_disease.lower()\n",
    "\n",
    "        # Compare predicted and actual diseases\n",
    "        if predicted_disease == actual_disease:\n",
    "            correct_predictions += 1\n",
    "        else:\n",
    "            mismatched_cases.append({\n",
    "                \"Symptoms\": symptoms,\n",
    "                \"Actual Disease\": actual_disease,\n",
    "                \"Predicted Disease\": predicted_disease\n",
    "            })\n",
    "\n",
    "    # Calculate accuracy\n",
    "    accuracy = correct_predictions / total_predictions\n",
    "    return accuracy, mismatched_cases\n",
    "\n",
    "# File path to the test dataset\n",
    "test_file_path = \"symptom_diseases_test.csv\"\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy, mismatched_cases = evaluate_model(test_file_path, vectorstore, model, tokenizer)\n",
    "\n",
    "# Display the results\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "if mismatched_cases:\n",
    "    print(\"\\nMismatched Cases:\")\n",
    "    for case in mismatched_cases:\n",
    "        print(f\"Symptoms: {case['Symptoms']}\")\n",
    "        print(f\"Actual Disease: {case['Actual Disease']}\")\n",
    "        print(f\"Predicted Disease: {case['Predicted Disease']}\")\n",
    "        print(\"-\" * 50)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
